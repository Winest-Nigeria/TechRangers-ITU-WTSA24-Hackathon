{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pypdf\n",
    "!pip install gpt4all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual Data Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pypdf\n",
    "from io import BytesIO\n",
    "from gpt4all import GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def download_pdf_from_url(pdf_url):\n",
    "    response = requests.get(pdf_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download the PDF: {response.status_code}\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_content):\n",
    "    reader = pypdf.PdfReader(BytesIO(pdf_content))\n",
    "    text = \"\"\n",
    "    for page_num in range(len(reader.pages)):\n",
    "        page = reader.pages[page_num]\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    # Basic cleaning: remove extra spaces and newlines\n",
    "    cleaned_text = text.replace('\\n', ' ').replace('\\r', '').strip()\n",
    "    # You can also add rules to remove unwanted headers, footers, or metadata\n",
    "    return cleaned_text\n",
    "\n",
    "pdf_url = \"https://www.itu.int/en/ITU-T/focusgroups/an/Documents/Use-case-AN.pdf\"\n",
    "pdf_content = download_pdf_from_url(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pdf_content = clean_text(extract_text_from_pdf(pdf_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, max_chars):\n",
    "    \"\"\"\n",
    "    Split the text into smaller chunks, each within the max_chars limit.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), max_chars):\n",
    "        chunk = text[i:i + max_chars]\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "def query_gpt4all_for_chunk(chunk, query):\n",
    "    \"\"\"\n",
    "    Query the GPT4All model for a single chunk of text.\n",
    "    \"\"\"\n",
    "    model = GPT4All(model_name=\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
    "    prompt = f\"The following is a chunk of the content of a PDF:\\n\\n{chunk}\\n\\nAnswer the following question based on this chunk:\\n\\n{query}\"\n",
    "    response = model.generate(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualizing Input for Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "MAX_CHARS = 1000\n",
    "model = GPT4All(model_name=\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
    "if pdf_content:\n",
    "    # Step 2: Split the PDF content into chunks\n",
    "    chunks = split_text_into_chunks(pdf_content, MAX_CHARS)\n",
    "\n",
    "    # Step 3: Query the GPT4All model for each chunk and gather responses\n",
    "    question = \"What is the document about?\"\n",
    "    all_responses = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"\\nProcessing chunk {i + 1}/{len(chunks)}...\")\n",
    "        response = query_gpt4all_for_chunk(chunk, question)\n",
    "        all_responses.append(response)\n",
    "\n",
    "    # Step 4: Combine and display the responses\n",
    "    combined_response = \"\\n\".join(all_responses)\n",
    "    print(\"\\nCombined GPT-4All Responses:\\n\", combined_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "question=\"What are the technological gaps in this ITU document?\"\n",
    "gpt_response= query_gpt4all(question, question)\n",
    "print('response:',gpt_response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
